
<div align="center">

# ğŸ¯ Custom YOLOv8 Object Detection Pipeline  
**End-to-End Deep Learning for Real-World Applications**

A complete object detection solution using [Ultralytics YOLOv8](https://github.com/ultralytics/ultralytics) with custom dataset support, training, and evaluation.



</div>

---

<p align="center">
  <!-- Framework -->
  <img src="https://img.shields.io/badge/Python-3.8+-blue?style=for-the-badge&logo=python&logoColor=white" />
  <img src="https://img.shields.io/badge/PyTorch-Deep%20Learning-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white" />
  <img src="https://img.shields.io/badge/YOLOv8-Object%20Detection-00FFFF?style=for-the-badge" />

  <!-- Annotation -->
  <img src="https://img.shields.io/badge/Label%20Studio-Data%20Annotation-FF6B6B?style=for-the-badge&logo=label-studio&logoColor=white" />

  <!-- Processing -->
  <img src="https://img.shields.io/badge/OpenCV-Image%20Processing-5C3EE8?style=for-the-badge&logo=opencv&logoColor=white" />
  <img src="https://img.shields.io/badge/Pandas-Data%20Handling-150458?style=for-the-badge&logo=pandas&logoColor=white" />

  <!-- Deployment -->
  <img src="https://img.shields.io/badge/Git-Version%20Control-F05032?style=for-the-badge&logo=git&logoColor=white" />
</p>

---

## ğŸ“œ Project Overview

This pipeline provides a complete workflow for custom object detection:

1. **Dataset Collection**: Smartphone-captured images
2. **Annotation**: Label Studio for precise bounding boxes
3. **Preparation**: Auto-conversion to YOLO format
4. **Training**: Configurable YOLOv8 model training
5. **Evaluation**: Comprehensive metrics (mAP, PR curves)
6. **Deployment**: Ready-to-use model output

---

## ğŸŒŸ Key Features

- ğŸ“¸ **Custom Dataset Support** - Use your own images
- ğŸ·ï¸ **Label Studio Integration** - Streamlined annotation
- âš™ï¸ **Configurable Training** - Edit `config.yaml` for different models
- ğŸ“Š **Visual Evaluation** - PR curves, confusion matrices
- ğŸ”„ **Reproducible** - Version controlled with requirements

---

## ğŸ“‚ Project Structure

```mermaid
graph TD
    A[Data Collection] --> B[Label Studio Annotation]
    B --> C[prepare_yolo_dataset.py]
    C --> D[YOLO-formatted Dataset]
    D --> E[train.py]
    E --> F[Model Training]
    F --> G[evaluate.py]
    G --> H[Performance Metrics]
```

```text
project-root/
â”œâ”€â”€ config.yaml                  # Training configuration
â”œâ”€â”€ prepare_yolo_dataset.py      # Dataset preparation
â”œâ”€â”€ training/
â”‚   â”œâ”€â”€ train.py                 # Training script
â”‚   â””â”€â”€ my_model.pt             # Output model
â”œâ”€â”€ evaluate.py                  # Evaluation script
â”œâ”€â”€ data/                       # Organized dataset
â”‚   â”œâ”€â”€ train/images/           # Training images
â”‚   â”œâ”€â”€ train/labels/           # Training labels
â”‚   â”œâ”€â”€ val/images/             # Validation images
â”‚   â”œâ”€â”€ val/labels/             # Validation labels
â”‚   â””â”€â”€ data.yaml               # Dataset config
â””â”€â”€ runs/                       # Training outputs
```

---

## ğŸ› ï¸ Tech Stack

| Component       | Technology |
|----------------|------------|
| Framework      | YOLOv8 (PyTorch) |
| Annotation     | Label Studio |
| Data Processing | OpenCV, Pandas |
| Configuration  | YAML |
| Version Control | Git |

---

## ğŸ“¸ Sample Outputs

<p align="center">
  <img src="assets/training_curve.png" alt="Training Metrics" width="45%" />
  <img src="assets/detection_example.png" alt="Detection Example" width="45%" />
</p>

---

## ğŸš€ Getting Started

### âœ… Prerequisites
- Python 3.8+
- Ultralytics YOLOv8 (`pip install ultralytics`)
- Label Studio (for annotation)

### âš™ï¸ Setup
```bash
git clone https://github.com/shivamprasad1001/yolo-project.git
cd yolo-project
pip install -r requirements.txt
```

### ï¿½ Dataset Preparation
1. Annotate images in Label Studio (YOLO format)
2. Export as `data.zip`
3. Run:
```bash
python prepare_yolo_dataset.py
```

### ğŸ‹ï¸ Training
Edit `config.yaml` then:
```bash
python training/train.py
```

### ğŸ“Š Evaluation
```bash
python evaluate.py
```

---

## âš™ï¸ Configuration (`config.yaml`)

```yaml
# Model configuration
model: yolov8n.pt        # yolov8n/s/m/l/x
data: data/data.yaml      # Dataset config
epochs: 50               # Training epochs
imgsz: 640               # Image size
batch: 16                # Batch size
project: runs/train      # Output directory
name: custom             # Run name
```

---

## ğŸ” Security & Best Practices

- All training data remains local
- Model weights can be encrypted for deployment
- Git ignores sensitive training outputs

---

## ğŸš§ Future Roadmap

- [ ] TensorRT optimization for deployment
- [ ] Web-based annotation interface
- [ ] Automated hyperparameter tuning
- [ ] Docker support for easy setup

---

## ğŸ‘¨â€ğŸ’» Author

**Shivam Prasad**  
[GitHub](https://github.com/shivamprasad1001) | 
[LinkedIn](https://www.linkedin.com/in/shivamprasad1001)

---

## ğŸ“ License

MIT License - See [LICENSE](LICENSE) for details.
